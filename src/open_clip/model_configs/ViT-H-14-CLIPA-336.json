{
    "embed_dim": 1024,
    "vision_cfg": {
        "image_size": 336,
        "layers": 32,
        "width": 1280,
        "head_width": 80,
        "patch_size": 14,
        "act_kwargs":{
            "approximate": "tanh"
        },
        "no_ln_pre": true,
        "pool_type": "avg"
    },
    "text_cfg": {
        "context_length": 32,
        "vocab_size": 32000,
        "hf_tokenizer_name": "bert-base-uncased",
        "width": 1024,
        "heads": 16,
        "layers": 24,
        "act_kwargs":{
            "approximate": "tanh"
        },
        "pool_type": "last",
        "no_causal_mask": true
    }
}